# Arquitectura de Migraci贸n Inteligente

## El Problema: Migraci贸n de L贸gica de Plataforma

Este proyecto aborda la migraci贸n de pipelines de datos de nuestra **Plataforma 3.0** a la nueva **Plataforma 4.0**.

Los artefactos de la 3.0 consisten en una combinaci贸n de:
* **JSONs de Azure Data Factory (ADF):** Definen el flujo de orquestaci贸n.
* **Notebooks de Databricks:** Contienen la l贸gica de transformaci贸n en Python/Spark.

La Plataforma 4.0 desmantela esta estructura en favor de un conjunto de 8 o m谩s archivos YAML especializados (como `acl.yaml`, `metadata.yaml`, `pipeline.yaml`, etc.), cuya estructura depende del framework de destino.

---

## El Desaf铆o Central: L贸gica Condicional (Hopsflow vs. Brewtiful)

La complejidad de la traducci贸n radica en que la Plataforma 4.0 utiliza frameworks distintos basados en la capa de la Arquitectura Medallion:

* **Framework Hopsflow:** Se utiliza para pipelines de capa (brz, slv).
* **Framework Brewtiful:** Se utiliza para pipelines de capa Oro (gld).

Por lo tanto, el sistema de migraci贸n debe primero clasificar el pipeline 3.0 y luego generar un conjunto de artefactos completamente diferente basado en esa clasificaci贸n.

---

## La Soluci贸n: Una Arquitectura de Agente Robusta (LangGraph)

Para automatizar esta traducci贸n compleja, se dise帽贸 un agente basado en **LangGraph**. Esta arquitectura permite construir un flujo de trabajo por pasos, condicional, paralelizable y robusto.

---
#### Para comprender la estructura de la arquitectura, es fundamental definir los tres tipos de nodos que conforman esta soluci贸n.
## Tipos de Nodos en la Arquitectura

La estructura se compone de tres tipos principales de nodos:

### 1. Nodo-Herramienta (El Trabajador o Enrutador)
**驴Tiene LLM?** No.
**驴Tiene Tools?** No. El nodo *es* la herramienta (una sola funci贸n de Python).
**Prop贸sito:** Ejecutar tareas deterministas (mec谩nicas) o l贸gicas (enrutamiento if/else). No "piensa", solo "hace".
* **Ejemplos en nuestra arquitectura:**
    * `Read_Manifest_and_Check_API`
    * `Framework_Loader`
    * `Enrutador_de_Translators`
    * `Validator_Tool`
    * `Check Validation`
    * `Check Human Decision`
    * `Generator`
    * `Ruff Format`

### 2. Nodo-Agente Simple (El Especialista)
**驴Tiene LLM?** S铆.
**驴Tiene Tools?** No.
**Prop贸sito:** Ejecutar una tarea de "pensamiento" o traducci贸n altamente especializada. Su inteligencia est谩 100% enfocada en su prompt espec铆fico. No decide entre herramientas, solo ejecuta su 煤nica tarea de IA.
* **Ejemplos en nuestra arquitectura:**
    * `Schema_Normalizer`
    * Todos los 8+ Translators (ej. `ACLTranslator`, `PipelineTranslator`, etc.)
    * `CorrectorAgent`
    * `ReporterLogger`

### 3. Nodo-Agente con Herramientas (El Gerente)
**驴Tiene LLM?** S铆.
**驴Tiene Tools?** S铆. Se le proporciona un "cintur贸n de herramientas" (m煤ltiples funciones) que puede usar.
**Prop贸sito:** Ejecutar tareas din谩micas o exploratorias. El LLM (el "Gerente") decide qu茅 herramientas usar y en qu茅 orden para cumplir un objetivo complejo.
* **Ejemplos en nuestra arquitectura:**
    * `Data_Fetcher` (que decide si usar la `github_api_tool` o la `databricks_api_tool`)

---

## El Flujo Completo de la Arquitectura

Este flujo describe el procesamiento de un solo pipeline de la lista contenida en el manifiesto.

```mermaid

flowchart TD
    subgraph MigrationFlow
        
        %% --- 1. Start and Pre-Validation ---
        A["START - manifest.yaml"]:::flow --> B["1. Read_Manifest_and_Check_API, Reads manifest and credentials. Validates API connectivity"]:::tool

        %% --- 2. Extraction (Split into 2 Nodes) ---
        subgraph C_Fetcher ["2 Data_Fetcher_Agent_with_Tools"]
            direction TB

            N1_LLM[" LLM (Manager) Decides which tools to use"]
            subgraph Tools
                direction LR
                T1[" github_api_tool"]:::tool
                T2[" databricks_api_tool"]:::tool
            end
            N1_LLM --> T1
            N1_LLM --> T2
        end
        B --> C_Fetcher

        %% Node 2b: The Normalizer
        C_Normalizer["3. Schema_Normalizer -----(Simple Agent) ---------- LLM (Specialist) Translates and Classifies"]:::agent
        C_Fetcher --> C_Normalizer

        %% --- Routing ---
        D_Loader["4. Framework_Loader ------(Tool: Loads Hopsflow/Brewtiful templates)"]:::tool
        C_Normalizer --> D_Loader
        
        D_Router["5.Translator_Router --- (Tool: Lists parallel nodes based on bronze/slv/gld)"]:::tool
        D_Loader --> D_Router

        %% --- Parallel Branches ---
        P2["TransformationsTranslator"]:::agent
        D_Router -->|"slv / brz"| P2

        G1["NotebookTranslator"]:::agent
        RF["Ruff Format (TOOL)"]:::tool
        D_Router -->|"gld"| G1
        G1 --> RF

        P1["PipelineTranslator"]:::agent
        C1["ACLTranslator"]:::agent
        C2["MetadataTranslator"]:::agent
        C3["QualityTranslator"]:::agent
        C4["SyncTranslator"]:::agent
        C5["ObservabilityTranslator"]:::agent

        D_Router -->|"slv / brz/ gld"| P1
        D_Router -->|"slv / brz/ gld"| C1
        D_Router -->|"slv / brz/ gld"| C2
        D_Router -->|"slv / brz/ gld"| C3
        D_Router -->|"slv / brz/ gld"| C4
        D_Router -->|"slv / brz/ gld"| C5

        %% --- 5. Validation and Correction Loop ---
        V["6 Validator_Tool, Runs 'engineeringstore --validate-dags'"]:::tool
        P1 --> V
        C1 --> V
        C2 --> V
        C3 --> V
        C4 --> V
        C5 --> V
        P2 --> V
        RF --> V

        CV["7 Check Validation, 'engineeringstore' report OK?"]:::tool
        V --> CV
        
        COR["8 CorrectorAgent, Uses 'engineeringstore' output to fix artifacts (MAX 3 iter.)"]:::agent
        CV -->|"FAIL"| COR
        COR --> V

        %% --- 6. Human Approval ---
        HITL["9 Human_Approval_Node PAUSE: awaits final human approval"]:::human
        CV -->|"PASS"| HITL

        %% --- 7. Final Flow ---
        CH["10 Check Human Decision"]:::human
        HITL --> CH
        
        R["11. ReporterLogger Writes migration_summary.md"]:::agent
        CH -->|"APPROVE"| R
        
        GEN["12. Generator Pushes to target repository"]:::tool
        R --> GEN
        
        Z["END - Package Ready"]:::flow
        GEN --> Z

        %% --- 8. Exit on Rejection ---
        ZR["END - Rejected by Human"]:::flow
        CH -->|"REJECT"| ZR
    end

    %% --- STYLES ---
    classDef tool fill:#fff3b0,stroke:#806c00,stroke-width:1px,color:#000;
    classDef agent fill:#9fd5ff,stroke:#004d80,stroke-width:1px,color:#000;
    classDef agent_with_tools fill:#ffd8b1,stroke:#a15800,stroke-width:1px,color:#000;
    classDef human fill:#c8f7c5,stroke:#2b8000,stroke-width:1px,color:#000;
    classDef flow fill:#e0e0e0,stroke:#888,stroke-width:1px,color:#000;

```

### Paso 1: Read_Manifest_and_Check_API (Ingesta y Pre-Validaci贸n) (Opcional)
* **Tipo de Nodo:** Nodo-Herramienta (Puro Python) | **:::tool**
* **Inicio:** El flujo comienza cuando un humano invoca al agente con la ruta a un `manifest.yaml`.
* **Acci贸n:** Este nodo (una funci贸n de Python) lee el `manifest.yaml` para extraer:
    * La lista de pipelines a migrar (`pipelines_to_migrate`).
    * Las credenciales de API (`credentials`).
* **L贸gica:** Realiza un "pre-flight check" usando las credenciales para hacer "ping" a las APIs de GitHub y Databricks y confirmar la conectividad.
* **Actualizaci贸n de Estado:** El `GraphState` se actualiza con `credentials`, `api_connectivity_ok = True`, y la lista `pipelines_to_migrate`. El orquestador externo ahora iterar谩 sobre esta lista.

### Paso 2: Data_Fetcher
* **Tipo de Nodo:** Nodo-Agente con Herramientas (Gerente) | **:::agent_with_tools**
* **Acci贸n:** Este nodo toma las `credentials` y el `current_pipeline_data` (el primer 铆tem del manifiesto) del estado.
* **L贸gica (LLM):** El LLM recibe un prompt para "recolectar archivos". Para hacerlo, decide qu茅 herramientas de su cintur贸n usar:
    * *Ejemplo:*
    * Llama a `github_api_tool` para obtener el JSON de ADF.
    * Llama a `databricks_api_tool` para obtener el notebook.
* **Actualizaci贸n de Estado:** Guarda los artefactos 3.0 crudos en `state['raw_artifacts_3_0']`.

### Paso 3: Schema_Normalizer
* **Tipo de Nodo:** Nodo-Agente Simple (Especialista) | **:::agent**
* **Acci贸n:** Este nodo se activa despu茅s del `Data_Fetcher`. Toma los `raw_artifacts_3_0` del estado.
* **L贸gica (LLM):** Llama al LLM (Especialista) con un prompt enfocado en dos tareas:
    1.  **Traducir:** Analizar los artefactos crudos y generar el `normalized_schema_v4.json`.
    2.  **Clasificar:** identificar `environment_type` ('slv' o 'gld'). -> (Este puede ser una funci贸n de python)
* **Actualizaci贸n de Estado:** Guarda `normalized_schema_v4` y `environment_type` en el estado.

```mermaid

graph TD
    subgraph "Extraction Flow (2 Steps)"
        direction LR
        
        %% --- Node 1: Agent with Tools ---
        subgraph A ["2. Data_Fetcher (Node-Agent with Tools)"]
            direction TB
            
            %% The "brain" of the agent
            N1_LLM[" LLM (Manager)<br/>Decides which tools to use"]
            
            %% The tools the brain can use
            subgraph "Tools"
                direction LR
                T1[" github_api_tool"]
                T2[" databricks_api_tool"]
                T3[" ... "]              
            end
            
            %% The brain uses the tools
            N1_LLM --> T1
            N1_LLM --> T2
            N1_LLM --> T3            
        end

        %% --- Node 2: Simple Agent ---
        B["3 Schema_Normalizer<br/>(Node-Simple Agent)<br/> LLM (Specialist)<br/>Translates and Classifies"]

        %% --- The Main Flow ---
        A --> B
    end

```

### Paso 4: Framework_Loader
* **Tipo de Nodo:** Nodo-Herramienta (Puro Python) | **:::tool**
* **Acci贸n:** Este nodo lee el `environment_type` del estado.
* **L贸gica:** Es un `if/else` que "hace checkout" de las plantillas correctas. Si es 'slv', carga los template files de Hopsflow. Si es 'gld', carga los de Brewtiful.
* **Actualizaci贸n de Estado:** Guarda las plantillas de texto crudo (ej. `state['pipeline_template']`) en el estado.
* **Comandos:**
    ```bash
    engineeringstore transformation --create-template-files (glds)
    engineeringstore ingestion --create-template-files (brz, slv)
    ```

### Paso 5: Enrutador_de_Translators
* **Tipo de Nodo:** Nodo-Herramienta (Enrutador Condicional) | **:::tool**
* **Acci贸n:** Lee el `environment_type` del estado.
* **L贸gica:** Es un `if/else` que define el plan de ejecuci贸n paralelo. Define una lista de traductores comunes (como `PipelineTranslator`, `ACLTranslator`, etc.) y a帽ade los traductores condicionales (`TransformationsTranslator` si es 'slv', `NotebookTranslator` si es 'gld').
* **Salida:** Retorna una lista de strings (ej. `["PipelineTranslator", "ACLTranslator", "NotebookTranslator"...]`) que LangGraph usar谩 para el siguiente paso.

```mermaid

graph TD
    subgraph "Extraction and Routing Flow"
        A["...Schema_Normalizer"] --> B["4 Framework_Loader<br/>(Tool: Loads Hopsflow/Brewtiful templates)"]
        B --> C["5 Translator_Router<br/>(Tool: Lists parallel nodes)"]
        C --> D["Parallel: Translators..."]
    end

    %% Color Styles
    style B fill:#fff3b0,stroke:#806c00,stroke-width:1px,color:#000;
    style C fill:#fff3b0,stroke:#806c00,stroke-width:1px,color:#000;

```

### Paso 6: Translators (El "Fan-Out" Paralelo)
* **Tipo de Nodo:** Nodos-Agente Simples (Especialistas) | **:::agent**
* **Acci贸n:** LangGraph toma la lista del enrutador y ejecuta todos esos nodos `Translator` en **paralelo**.
* **L贸gica (LLM):** Cada nodo `Translator` (ej. `ACLTranslator`, `MetadataTranslator`, etc.) es un "Especialista" que toma el `normalized_schema_v4` y su plantilla correspondiente (cargada en el Paso 4) y genera el archivo YAML final.
* **Actualizaci贸n de Estado:** Cada nodo escribe en su propio campo del estado (ej. `state['acl_yaml'] = "..."`).

### Paso 7: Ruff Format
* **Tipo de Nodo:** Nodo-Herramienta (Puro Python) | **:::tool**
* **Acci贸n:** Este nodo se ejecuta solo en el branch 'gld', despu茅s del `NotebookTranslator`.
* **L贸gica:** Es una funci贸n simple que toma el c贸digo del `generated_notebooks` y lo formatea usando la herramienta `ruff` para asegurar la calidad del c贸digo.
* **Actualizaci贸n de Estado:** Sobrescribe `state['generated_notebooks']` con el c贸digo formateado.

### Paso 8: Validator_Tool (Validaci贸n Espec铆fica)
* **Tipo de Nodo:** Nodo-Herramienta (Trabajador) | **:::tool**
* **Acci贸n (Sincronizaci贸n):** Act煤a como una barrera **"Fan-In"**. Espera a que todos los traductores (Paso 6) y el formateador (Paso 7, si se ejecut贸) terminen.
* **L贸gica (Herramienta):** Ejecuta el comando `engineeringstore --validate-dags` sobre los artefactos generados.
* **Actualizaci贸n de Estado:** Captura la salida de texto (stdout/stderr) y la guarda en `state['validator_output']`.

### Paso 9: Check Validation (Bucle de Auto-Correcci贸n)
* **Tipo de Nodo:** Nodo-Herramienta (Enrutador Condicional) | **:::tool**
* **Acci贸n:** Lee el `state['validator_output']` y el `state['retry_count']`.
* **L贸gica (Fallo):** Si el `validator_output` contiene errores y `retry_count` es menor a 3:
    * Incrementa `retry_count` y establece `validation_passes = False`.
    * Desv铆a el flujo al `CorrectorAgent`.
* **L贸gica (xito):** Si no hay errores:
    * Establece `validation_passes = True`.
    * Desv铆a el flujo al `Human_Approval_Node`.

### Paso 10: CorrectorAgent (El Corrector)
* **Tipo de Nodo:** Nodo-Agente Simple (Especialista) | **:::agent**
* **Acci贸n:** Se activa en el bucle "FAIL".
* **L贸gica (LLM):** Recibe un prompt muy espec铆fico que contiene el error (`validator_output`) y los artefactos fallidos del estado. Genera un nuevo conjunto de artefactos corregidos.
* **Actualizaci贸n de Estado:** Sobrescribe los artefactos en el estado y el flujo vuelve al **Paso 8 (Validator_Tool)** para una nueva validaci贸n.

### Paso 11: Human_Approval_Node (Parada Obligatoria) (Solo en fase de prueba)
* **Tipo de Nodo:** Nodo de Pausa (Humano) | **:::human**
* **Acci贸n:** Se activa solo despu茅s de una validaci贸n exitosa ("PASS").
* **L贸gica:** **PAUSA** la ejecuci贸n del grafo, cumpliendo el requisito de que "un humano tiene que validar el resultado final". (Esto puede ser solo para el per铆odo de prueba).
* **Interacci贸n:** El sistema espera a que un humano actualice `state['human_approval_decision']` con "APPROVE" o "REJECT".

### Paso 12: Check Human Decision (Aprobaci贸n Final)
* **Tipo de Nodo:** Nodo-Herramienta (Enrutador Condicional) | **:::human**
* **Acci贸n:** Se reanuda cuando `human_approval_decision` se llena.
* **L贸gica:** Lee la decisi贸n.
    * Si es "APPROVE", retorna la ruta "APPROVE".
    * Si es "REJECT", retorna la ruta "REJECT".

### Paso 13: ReporterLogger (El Auditor)
* **Tipo de Nodo:** Nodo-Agente Simple (Especialista) | **:::agent**
* **Acci贸n:** Se activa solo en el flujo "APPROVE".
* **L贸gica (LLM):** Genera el `migration_summary.md` documentando todo el proceso, la validaci贸n exitosa y la aprobaci贸n humana.
* **Actualizaci贸n de Estado:** Guarda el .md en `state['migration_summary_md']`.

### Paso 14: Generator (El Desplegador)
* **Tipo de Nodo:** Nodo-Herramienta (Trabajador) | **:::tool**
* **Acci贸n:** Se activa despu茅s del `ReporterLogger`.
* **L贸gica:** Recolecta todos los artefactos aprobados (.yaml, notebooks) y el reporte (.md) del estado. Usando las `credentials` del estado, realiza un `git push` para subir estos archivos al repositorio 4.0 objetivo.
* **Salida:** El flujo termina en `END (Package Ready)`.

### Paso 15: Bucle del Manifiesto
* **Acci贸n:** Una vez que el flujo termina (ya sea en `END (Package Ready)` o `END (Rejected by Human)`), el orquestador externo vuelve al **Paso 2** para procesar el siguiente 铆tem en la lista `pipelines_to_migrate` del manifiesto, repitiendo todo el proceso.

---

## Propuesta de State (GraphState)

El `GraphState` es el 煤nico objeto de datos y la fuente central de verdad para nuestro flujo de migraci贸n.

Es un diccionario de Python que contiene toda la informaci贸n de un pipeline mientras se procesa: entradas, credenciales, artefactos intermedios (como el schema), todos los YAMLs generados, los reportes de validaci贸n y las decisiones humanas.

En este proyecto, el `GraphState` nos permite:

* **Comunicaci贸n:** Es la forma en que los nodos se pasan informaci贸n (ej. el Extractor le pasa el schema a los Translators).
* **Control de Flujo:** Permite a los enrutadores tomar decisiones l贸gicas al leer su contenido (ej. "si `environment_type` es 'gld', ir a `NotebookTranslator`").
* **Paralelismo:** Habilita que los 8 Translators se ejecuten al mismo tiempo, ya que cada uno escribe en su propio campo aislado dentro del estado.
* **Robustez (Bucles):** Es lo que hace posible el bucle de auto-correcci贸n, al persistir el `validator_output` y el `retry_count` para que el `CorrectorAgent` sepa qu茅 arreglar.
* **Interacci贸n Humana:** Permite que el grafo se pause (esperando que se llene `human_approval_decision`) y se reanude m谩s tarde, habilitando la validaci贸n humana.

```python


from typing import TypedDict, List, Dict, Any, Optional

class MigrationGraphState(TypedDict):
    """
    Este es el 'Estado' central que fluye a trav茅s del grafo de migraci贸n.
    Refleja la arquitectura de varios pasos para la extracci贸n y el enrutamiento.
    """

    # --- SECCIN 1: ENTRADAS INICIALES Y MANIFIESTO ---
    # Llenado al invocar el grafo
    
    manifest_path: str  # La ruta al 'manifest.yaml' que define el lote
    
    # --- SECCIN 2: ESTADO DEL LOTE Y PRE-VALIDACIN ---
    # Llenado por el nodo 'Read_Manifest_and_Check_API'
    
    credentials: Optional[Dict[str, str]]    # Credenciales de API (GitHub, Databricks)
    api_connectivity_ok: bool                # Resultado del 'pre-flight check'
    pipelines_to_migrate: List[Dict[str, Any]] # La lista de trabajo del manifiesto
    
    # El pipeline individual que se est谩 procesando actualmente en el bucle
    current_pipeline_data: Optional[Dict[str, Any]] 

    
    # --- SECCIN 3: ESTADO DE EXTRACCIN (EN 2 PASOS) ---
    # Llenado por el 'Data_Fetcher' (Paso 2a)
    raw_artifacts_3_0: Optional[Dict[str, Any]] # {"adf_json": "...", "notebook_code": "..."}
    
    # Llenado por el 'Schema_Normalizer' (Paso 2b)
    normalized_schema_v4: Optional[Dict[str, Any]] # El JSON limpio, fuente de verdad
    environment_type: Optional[str]                # 'slv' o 'gld'

    
    # --- SECCIN 4: PLANTILLAS DE FRAMEWORK (HOPSFLOW/BREWTIFUL) ---
    # Llenado por el 'Framework_Loader' (Paso 3a)
    
    pipeline_template: Optional[str]         # El texto de la plantilla 'hopsflow_pipeline_template.yaml'
    transform_template: Optional[str]        # El texto de la plantilla 'hopsflow_transformations_template.yaml'
    notebook_template: Optional[str]         # El texto de la plantilla 'brewtiful_notebook_template.py'

    
    # --- SECCIN 5: ARTEFACTOS DE TRADUCCIN (SALIDAS) ---
    # Llenados en paralelo por los nodos 'Translator' (Paso 6)

    # Comunes
    acl_yaml: Optional[str]              #
    metadata_yaml: Optional[str]         #
    quality_yaml: Optional[str]          #
    sync_yaml: Optional[str]             #
    observability_yaml: Optional[str]    #
    pipeline_yaml: Optional[str]         #

    # Condicional 'slv'
    transformations_yaml: Optional[str]  #

    # Condicional 'gld' (salida de NotebookTranslator + Ruff)
    generated_notebooks: Optional[List[str]] #

    
    # --- SECCIN 6: VALIDACIN Y BUCLE DE CORRECCIN ---
    # Llenado por 'Validator_Tool', 'Check Validation' y 'CorrectorAgent'
    
    validator_output: Optional[str]      # El stdout/stderr crudo de 'engineeringstore --validate-dags'
    validation_passes: bool              # True/False, basado en el an谩lisis del 'validator_output'
    retry_count: int                     # Contador para el bucle de correcci贸n (inicia en 0)


    # --- SECCIN 7: APROBACIN HUMANA ---
    # Llenado por el 'Human_Approval_Node'
    
    human_approval_decision: Optional[str] # La decisi贸n del humano ('APPROVE' o 'REJECT')


    # --- SECCIN 8: SALIDAS FINALES Y AUDITORA ---
    # Llenado por 'ReporterLogger' y 'Generator'
    
    migration_summary_md: Optional[str]  # El resumen de auditor铆a .md
    
    # El resultado del push final al repositorio 4.0
    push_status: Optional[str]           # (ej. "xito: commit 7a8b9c1" o "Fallo: ...")

```

