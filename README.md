# ðŸº BrewBridge AI

> **Bridging legacy data to the new platform â€” one pipeline at a time.**

BrewBridge AI is an **intelligent agentic framework** designed to **automate data pipeline migrations** from legacy platforms (e.g., Data Platform 3.0, COBOS) to the modern **Platform 4.0** ecosystem â€” powered by **Hopsflow** and **Brewtiful** frameworks.

This project leverages **LangGraph** to orchestrate a hybrid workflow of deterministic tools, LLM-based translators, and human-in-the-loop validation nodes â€” delivering scalable, auditable, and production-grade migrations.

---

## ðŸ§© Key Highlights

- **End-to-end intelligent migration** from legacy systems to Platform 4.0.
- **Single agent flow** handling classification, extraction, translation, validation, and deployment.
- **Framework-aware architecture**: adapts automatically for Hopsflow (bronze/silver) or Brewtiful (gold) pipelines.
- **Human-in-the-loop approval** for governance and quality assurance.
- **Extensible â€œSource + Strategyâ€ pattern** supporting multiple origins (GitHub, ADF, SQL, JSON, etc.).
- **Deployable as a package**: works locally, in Databricks Jobs, or via CI/CD.

---

## âš™ï¸ Architecture Overview

The BrewBridge agent operates through a **LangGraph-based state machine** composed of three types of nodes:

| Node Type | Description | Example |
|------------|--------------|----------|
| ðŸ› ï¸ **Tool Node** | Deterministic, procedural Python function. No LLM. | `Read_Manifest`, `Validator_Tool` |
| ðŸ§  **Agent Node** | LLM-powered specialist with a single-purpose prompt. | `Schema_Normalizer`, `Translator` |
| ðŸ‘¤ **Human Node** | Human approval or decision checkpoint. | `Human_Approval_Node` |

Each pipeline migration runs through the full agentic flow:
> Manifest â†’ Extraction â†’ Normalization â†’ Translation â†’ Validation â†’ Human Approval â†’ Deployment

---

## ðŸ§  Intelligent Extraction Layer

Extraction is handled by a **single `ExtractorTool`**, which dynamically loads **Source Handlers** and **Framework Strategies** depending on the origin framework (e.g., 3.0, COBOS).

### ðŸ”Œ Source Handlers
Reusable connectors that know **how** to access a data source:
- `GitHubSourceHandler`
- `ADFSourceHandler`
- `SQLSourceHandler`
- `JSONSourceHandler`

### ðŸ§© Strategies
Define **what** to extract and **how** to interpret it for each framework:
- `GitHub3_0Strategy`, `GitHubCobosStrategy`
- `ADF3_0Strategy`, `SQLCobosStrategy`

This pattern isolates framework-specific logic while keeping the extraction flow unified and extensible.

---

## ðŸ§± Folder Structure

```plaintext
.
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ cache
â”‚Â Â  â”œâ”€â”€ brewtiful
â”‚Â Â  â”‚Â Â  â””â”€â”€ .gitkeep
â”‚Â Â  â””â”€â”€ hopsflow
â”‚Â Â      â””â”€â”€ .gitkeep
â”œâ”€â”€ inputs
â”‚Â Â  â”œâ”€â”€ .gitkeep
â”‚Â Â  â””â”€â”€ samples
â”‚Â Â      â”œâ”€â”€ normalized_ingestion_logistics_single_task.json
â”‚Â Â      â””â”€â”€ normalized_ingestion_sales_multi_task.json
â”œâ”€â”€ LICENSE
â”œâ”€â”€ migration_flow.png
â”œâ”€â”€ outputs
â”‚Â Â  â”œâ”€â”€ .gitkeep
â”‚Â Â  â””â”€â”€ 2025-11-08_pipeline_x
â”‚Â Â      â””â”€â”€ raw_artifacts
â”‚Â Â          â””â”€â”€ .gitkeep
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ RFC.md
â”œâ”€â”€ src
â”‚Â Â  â””â”€â”€ brewbridge
â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â”œâ”€â”€ config.py
â”‚Â Â      â”œâ”€â”€ core
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ base_nodes.py
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ graph_builder.py
â”‚Â Â      â”‚Â Â  â””â”€â”€ state.py
â”‚Â Â      â”œâ”€â”€ domain
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ agents
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ translators
â”‚Â Â      â”‚Â Â  â”‚Â Â      â””â”€â”€ __init__.py
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ extractor_strategies
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â      â”‚Â Â  â”‚Â Â  â”œâ”€â”€ cobos_strategy.py
â”‚Â Â      â”‚Â Â  â”‚Â Â  â””â”€â”€ framework_3_0_strategy.py
â”‚Â Â      â”‚Â Â  â””â”€â”€ tools
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ engineeringstore_input_builder.py
â”‚Â Â      â”‚Â Â      â”œâ”€â”€ extractor
â”‚Â Â      â”‚Â Â      â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â      â”‚Â Â      â”‚Â Â  â””â”€â”€ 3.0
â”‚Â Â      â”‚Â Â      â”‚Â Â      â””â”€â”€ __init__.py
â”‚Â Â      â”‚Â Â      â””â”€â”€ template_creator.py
â”‚Â Â      â”œâ”€â”€ humans
â”‚Â Â      â”‚Â Â  â””â”€â”€ __init__.py
â”‚Â Â      â”œâ”€â”€ infrastructure
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ engineeringstore_cli.py
â”‚Â Â      â”‚Â Â  â””â”€â”€ logger.py
â”‚Â Â      â”œâ”€â”€ main.py
â”‚Â Â      â”œâ”€â”€ prompts
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ schema_normalizer.md
â”‚Â Â      â”‚Â Â  â””â”€â”€ translators
â”‚Â Â      â”‚Â Â      â””â”€â”€ __init__.py
â”‚Â Â      â””â”€â”€ utils
â”‚Â Â          â”œâ”€â”€ __init__.py
â”‚Â Â          â””â”€â”€ exceptions.py
â”œâ”€â”€ tests
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ conftest.py
â”‚Â Â  â”œâ”€â”€ integration
â”‚Â Â  â”‚Â Â  â””â”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ manual
â”‚Â Â  â”‚Â Â  â””â”€â”€ test_engineeringstore_cli_transformation_ingestion.py
â”‚Â Â  â””â”€â”€ unit
â”‚Â Â      â”œâ”€â”€ __init__.py
â”‚Â Â      â”œâ”€â”€ test_extraction.py
â”‚Â Â      â””â”€â”€ test_normalization.py
â”œâ”€â”€ tree.md
â””â”€â”€ uv.lock

````

---

## ðŸ§° Setup & Execution

### Installation

```bash
uv sync
uv pip install -e .
```

AquÃ­ tienes la secciÃ³n **limpia, final y perfecta**, sin los puntos 6 y 7.
Lista para pegar directo en tu README.

---

# ðŸ“Š MLflow Local Observability Setup

To enable the new **Observability Layer**, every developer must run a **local MLflow Tracking Server**.
This ensures a consistent environment for inspecting traces, artifacts, metrics, YAML diffs, and node-level behaviors across the entire BrewBridge migration flow.

This setup is lightweight, reproducible, and fully aligned with the teamâ€™s local development workflow.

---

## ðŸ”§ 1. Install Dependencies (via `uv`)

All MLflow dependencies are already defined in the project configuration.

Every developer simply needs to run:

```bash
uv sync
```

This installs MLflow and all required observability packages into the virtual environment.

---

## ðŸš€ 2. Start the Local MLflow Tracking Server

From the project root:

```bash
mlflow server \
  --host 127.0.0.1 \
  --port 8080 \
  --backend-store-uri sqlite:///mlflow.db \
  --default-artifact-root ./mlruns
```

This launches:

* **SQLite** â†’ local metadata storage
* `./mlruns/` â†’ artifact store
* MLflow UI â†’ [http://127.0.0.1:8080](http://127.0.0.1:8080)

> Every developer runs this locally.
> Zero cloud dependency. No credentials required. Full autonomy.

---

## ðŸ·ï¸ 3. Configure BrewBridge to Log to Local MLflow

Add this to your local `.env` (ignored by Git):

```
MLFLOW_TRACKING_URI=http://127.0.0.1:8080
MLFLOW_EXPERIMENT_NAME=brewbridge_observability
```

The observability layer will automatically route all traces and metrics to your local MLflow instance.

---

## ðŸ§ª 4. Validate the Setup

Run:

```python
import dotenv
import mlflow

load_dotenv()

print("Tracking:", mlflow.get_tracking_uri())

with mlflow.start_run():
    mlflow.log_param("env_test", "ok")
    mlflow.log_metric("latency_ms", 123)
```

Open the UI:
ðŸ‘‰ [http://127.0.0.1:8080](http://127.0.0.1:8080)

You should see the test run.

---

## ðŸ³ 5. Optional â€“ Docker Compose

If the team prefers a containerized environment, add:

```yaml
# docker-compose.yml
services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "8080:8080"
    volumes:
      - ./mlruns:/mlruns
      - ./mlflow.db:/mlflow.db
    command: >
      mlflow server
      --host 0.0.0.0
      --port 8080
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlruns
```

Start it:

```bash
docker compose up -d
```

### Run Migration

```bash
uv run brewbridge --manifest inputs/manifest.yaml
```

### Test Suite

```bash
pytest -v
```

---

## ðŸ“¦ Packaging

BrewBridge AI is an installable Python package following the `src/` layout.
You can build and distribute it using:

```bash
uv build
uv pip install dist/brewbridge-0.1.0-py3-none-any.whl
```

---

## ðŸ§­ Project Vision

> BrewBridge AI is designed not just to migrate, but to **learn and adapt**.
> Future iterations will integrate telemetry, anomaly detection, and self-healing translation logic for continuous improvement.

---

**Developed by:** Brewdat Platform Team

**Ecosystem:** AB InBev â€“ BrewDat 4.0 / Hopsflow / Brewtiful

